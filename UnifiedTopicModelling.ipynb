{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d3ef077c7d4c5fa080efdd0ad7de7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Language to use for topic extraction:', index=1, options=('English', 'Chinese'), value='â€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "widgets.Dropdown(\n",
    "    options=['English', 'Chinese'],\n",
    "    value='Chinese',\n",
    "    description='Language to use for topic extraction:',\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, Features, Value, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(sources=['JOIN Proposals', 'iVoting Proposals'], text_columns=['title', 'proposal'], language='en'):\n",
    "    all_data = pd.read_excel('data/JOIN_iVoting_Proposals_categorized.xlsx')\n",
    "    all_data['label'] = all_data['Category']\n",
    "    training_dataset = pd.DataFrame(data={\n",
    "        'text': all_data[[column + '_' + language for column in text_columns]].apply(lambda row: '_'.join(row.values.astype(str)), axis=1),\n",
    "        'label': all_data['Category']\n",
    "    })\n",
    "    # check for int in text column\n",
    "    return Dataset.from_pandas(training_dataset, features=Features({'text': Value('string'), 'label': ClassLabel(names=all_data['Category'].unique().tolist())}))\n",
    "\n",
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset.set_format(type=\"torch\", columns=[\"text\", \"label\"])\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/korjakow/.cache/pypoetry/virtualenvs/03-urbandevelopmenttaiwan-HQCD10_a-py3.11/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "/home/korjakow/.cache/pypoetry/virtualenvs/03-urbandevelopmenttaiwan-HQCD10_a-py3.11/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: auto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMoritzLaurer/mDeBERTa-v3-base-mnli-xnli\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model)\n\u001b[0;32m----> 8\u001b[0m pipeline \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39;49mpipeline(\u001b[39m\"\u001b[39;49m\u001b[39mzero-shot-classification\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMoritzLaurer/mDeBERTa-v3-base-mnli-xnli\u001b[39;49m\u001b[39m\"\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/03-urbandevelopmenttaiwan-HQCD10_a-py3.11/lib/python3.11/site-packages/transformers/pipelines/__init__.py:988\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m device\n\u001b[0;32m--> 988\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline_class(model\u001b[39m=\u001b[39;49mmodel, framework\u001b[39m=\u001b[39;49mframework, task\u001b[39m=\u001b[39;49mtask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/03-urbandevelopmenttaiwan-HQCD10_a-py3.11/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:88\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__init__\u001b[0;34m(self, args_parser, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, args_parser\u001b[39m=\u001b[39mZeroShotClassificationArgumentHandler(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args_parser \u001b[39m=\u001b[39m args_parser\n\u001b[0;32m---> 88\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     89\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentailment_id \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     90\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m     91\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFailed to determine \u001b[39m\u001b[39m'\u001b[39m\u001b[39mentailment\u001b[39m\u001b[39m'\u001b[39m\u001b[39m label id from the label2id mapping in the model config. Setting to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m-1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/03-urbandevelopmenttaiwan-HQCD10_a-py3.11/lib/python3.11/site-packages/transformers/pipelines/base.py:781\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m=\u001b[39m framework\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(device, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m device \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 781\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    784\u001b[0m     \u001b[39m# `accelerate` device map\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     hf_device_map \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mhf_device_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/03-urbandevelopmenttaiwan-HQCD10_a-py3.11/lib/python3.11/site-packages/transformers/modeling_utils.py:1900\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1896\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1897\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1898\u001b[0m     )\n\u001b[1;32m   1899\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1900\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/03-urbandevelopmenttaiwan-HQCD10_a-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1126\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1040\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves and/or casts the parameters and buffers.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m \u001b[39m    This can be called as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \n\u001b[1;32m   1124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1126\u001b[0m     device, dtype, non_blocking, convert_to_format \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49m_parse_to(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1128\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (dtype\u001b[39m.\u001b[39mis_floating_point \u001b[39mor\u001b[39;00m dtype\u001b[39m.\u001b[39mis_complex):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: auto"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\", device=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 'Law & Justice ',\n",
       " 'Transport',\n",
       " 'Social ',\n",
       " 'Military and Natonal Security ',\n",
       " 'Environment & Climate',\n",
       " 'Finance ',\n",
       " 'Education ',\n",
       " 'Energy ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m----> 2\u001b[0m     sequences \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m      3\u001b[0m         batch[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m         candidate_labels\u001b[39m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mLaw & Justice \u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mTransport\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mSocial \u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mMilitary and National Security \u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mEnvironment & Climate\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mFinance \u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mEducation \u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mEnergy \u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(sequences[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(sequences[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    sequences = pipeline(\n",
    "        batch[\"text\"],\n",
    "        candidate_labels=[\n",
    " 'Law & Justice ',\n",
    " 'Transport',\n",
    " 'Social ',\n",
    " 'Military and National Security ',\n",
    " 'Environment & Climate',\n",
    " 'Finance ',\n",
    " 'Education ',\n",
    " 'Energy '],\n",
    "    )\n",
    "    print(sequences[0]['sequence'])\n",
    "    print(sequences[0]['labels'])\n",
    "    print(sequences[0]['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03-urbandevelopmenttaiwan-HQCD10_a-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
